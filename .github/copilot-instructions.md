# ğŸ§  Copilot Instructions â€” Systematic Macro Credit Project (VS Code Agent Mode)

## ğŸ¯ Purpose

These instructions optimize **Copilot Chat and inline completions** in **VS Code Agent mode** (Claude Sonnet 4.5 / GPTâ€‘5) for the *Systematic Macro Credit* project.  
The goal is to ensure the AI assistant generates **clean, modular, and reproducible** Python code aligned with project architecture and investment research standards.

---

## ğŸ§© Project Overview

You are working within a **systematic fixedâ€‘income research environment**.  
The framework supports:
- Development and testing of **pilot investment strategies** (e.g., CDX overlay).
- Modular architecture for **data**, **model**, **backtest**, **visualization**, and **persistence** layers.
- Reproducible, documented, and versionâ€‘controlled research.

### Repository Layout

```
src/macrocredit/
  data/               # Loaders, cleaning, transformation
  models/             # Signal & strategy logic
  backtest/           # Backtesting engine and risk tracking
  visualization/      # Plotly & Streamlit dashboards
  persistence/        # Parquet & JSON I/O utilities
  config/             # Paths, constants, environment
  __init__.py         # Package initialization
  main.py             # CLI entry point / notebook runner

tests/                # Unit tests for reproducibility
  data/
  models/
  backtest/
  visualization/
  persistence/

.docs/                # Documentation and strategy specs
  cdx_overlay_strategy.md # Investment strategy context
.github/              # GitHub workflows and agent instructions
pyproject.toml        # Project dependencies and build system
README.md             # Project overview and setup instructions
```

---

## âš™ï¸ Environment Standards

- **Python:** 3.13  
- **Type Hints:** Use modern Python 3.13 syntax (`str | None` instead of `Optional[str]`, `int | float` instead of `Union[int, float]`)
- **Environment:** managed with [`uv`](https://docs.astral.sh/uv/)  
- **Linting / Formatting:** `ruff`, `black`, `mypy`
- **Testing:** `pytest`
- **Docs:** `mkdocs` or `sphinx`
- **Visualization:** `plotly`, `streamlit`

All dependencies live in `pyproject.toml`.  
Use relative imports and avoid global state.

---

## ğŸ’¡ Agent Behavior Guidelines

### General
1. **Always prioritize modular, PEPÂ 8â€‘compliant, typeâ€‘annotated code.**
2. **Never mix strategy logic with infrastructure code.**
3. **Always document functions and classes using NumPyâ€‘style docstrings.**
4. **Propose structured changes â€” not isolated code fragments.**
5. **Assume collaboration**: other developers must read and extend your code easily.

### Style
- Follow **PEP 8** and **type hints** strictly.
- Use **Python 3.13 type syntax**: `str | None` not `Optional[str]`, `int | float` not `Union[int, float]`.
- Use **built-in generics**: `list[str]` not `List[str]`, `dict[str, Any]` not `Dict[str, Any]`.
- Use **black** and **ruff** formatting conventions.
- Add **docstrings** and comments explaining rationale and data flow.

### Documentation Example
```python
def compute_spread_momentum(spread: pd.Series, window: int = 5) -> pd.Series:
    """
    Compute shortâ€‘term momentum in CDX spreads using zâ€‘score normalization.

    Parameters
    ----------
    spread : pd.Series
        Daily CDX spread levels.
    window : int, default 5
        Rolling lookback period in days.

    Returns
    -------
    pd.Series
        Normalized momentum signal.
    """
```

---

## ğŸ§  Agent Context Hints for Claude Sonnet / GPTâ€‘5

| Context | Preferred Behavior |
|----------|--------------------|
| Editing `/data/` | Focus on reproducible data loading, cleaning, and transformation. Avoid strategy logic. |
| Editing `/models/` | Focus on signal functions and strategy modules. Use clean abstractions (`BaseModel`). |
| Editing `/backtest/` | Implement transparent, deterministic backtest logic. Include metadata logging. |
| Editing `/visualization/` | Generate reusable Plotly/Streamlit components. Separate plotting from computation. |
| Editing `/persistence/` | Handle Parquet/JSON I/O and registry management. No database dependencies. |
| Editing `/tests/` | Write unit tests for determinism, type safety, and reproducibility. |

When generating code, the assistant should **infer module context from file path** and **adhere to functional boundaries** automatically.

---

## âœ… Completion Optimization Rules

- Always suggest **imports relative to project structure**, not absolute paths.  
- Provide **runnable examples** with synthetic or minimal data.  
- Use **clear function and variable naming** (snake_case, descriptive).  
- When generating new modules, **include header comments** describing purpose and dependencies.  
- Include **type hints** and **unit test templates** by default.

### Example Ideal Output (inline completion)

```python
# models/cdx_overlay_model.py

from ..data.loader import load_market_data
from ..persistence.io import save_json
import pandas as pd

def compute_vix_cdx_gap(
    vix_df: pd.DataFrame,
    cdx_df: pd.DataFrame,
    lookback: int = 20
) -> pd.Series:
    """
    Compute the relative stress signal between equity vol (VIX) and CDX spreads.

    The signal identifies divergence between crossâ€‘asset risk sentiment.
    Positive values indicate VIX outpacing credit widening.

    Parameters
    ----------
    vix_df : pd.DataFrame
        VIX index levels with 'VIX' column.
    cdx_df : pd.DataFrame
        CDX index spreads with 'spread' column.
    lookback : int, default 20
        Rolling window for mean and std calculation.

    Returns
    -------
    pd.Series
        Normalized VIXâ€‘CDX gap signal.
        
    Notes
    -----
    Uses z-score normalization to make signals comparable across regimes.
    """
    vix_deviation = vix_df['VIX'] - vix_df['VIX'].rolling(lookback).mean()
    cdx_deviation = cdx_df['spread'] - cdx_df['spread'].rolling(lookback).mean()
    gap = vix_deviation - cdx_deviation
    return gap / gap.rolling(lookback).std()
```

---

## ğŸš« The Agent Should Never

- Use external databases or APIs (use Parquet/JSON only).  
- Use old typing syntax (`Optional`, `Union`, `List`, `Dict`) - always use Python 3.13+ style.
- Hardcode file paths or credentials.  
- Generate nonâ€‘deterministic results without a fixed random seed.  
- Mix backtest logic with data ingestion.  
- Produce undocumented or untyped code.  
- Add notebook cells or magic commands inside modules.  

---

## ğŸ§ª Testing & Logging Expectations

- All stochastic components must be **seeded deterministically**.  
- Every backtest or signal computation must log:  
  - Timestamp  
  - Parameters  
  - Version hash  
- Include lightweight tests for data I/O, signal correctness, and regression.  

Example:
```python
metadata = {
    "timestamp": datetime.now().isoformat(),
    "params": params_dict,
    "version": __version__,
}
save_json(metadata, "run_metadata.json")
```

---

## ğŸ”— Recommended Agent Prompts

When using Copilot Chat or VSÂ Code inline completions, prefer prompts like:

- â€œAdd a deterministic backtest class that tracks daily P&L and logs parameters.â€  
- â€œRefactor this data loader to follow project persistence standards.â€  
- â€œWrite unit tests for this model to ensure reproducible signal outputs.â€  
- â€œAdd Streamlit components to visualize signal performance.â€  

Avoid generic prompts like *â€œoptimize this codeâ€* â€” always specify layer and intent.

---

## ğŸ“˜ Summary

Copilot should behave like a **quantitative developer assistant**, not a strategy designer.  
It should:
- Maintain modularity, transparency, and reproducibility.
- Focus on infrastructure excellence and analytical clarity.
- Produce code ready for production research pipelines.

> Maintained by **stabilefrisur**.  
> Version 1.0 â€” Optimized for VSÂ Code Agent Mode (Claude SonnetÂ 4.5 / GPTâ€‘5)  
> OctoberÂ 2025
